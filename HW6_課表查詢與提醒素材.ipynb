{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371120h/PL-Repo.peng/blob/main/HW6_%E8%AA%B2%E8%A1%A8%E6%9F%A5%E8%A9%A2%E8%88%87%E6%8F%90%E9%86%92%E7%B4%A0%E6%9D%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä»£ç†è®Šæ•¸\n",
        "print(\"ç•¶å‰ HTTP_PROXY:\", os.environ.get('HTTP_PROXY'))\n",
        "print(\"ç•¶å‰ HTTPS_PROXY:\", os.environ.get('HTTPS_PROXY'))\n",
        "\n",
        "# æ¸…é™¤ä»£ç†è®Šæ•¸\n",
        "if 'HTTP_PROXY' in os.environ:\n",
        "    del os.environ['HTTP_PROXY']\n",
        "    print(\"å·²æ¸…é™¤ HTTP_PROXY\")\n",
        "if 'HTTPS_PROXY' in os.environ:\n",
        "    del os.environ['HTTPS_PROXY']\n",
        "    print(\"å·²æ¸…é™¤ HTTPS_PROXY\")\n",
        "if 'http_proxy' in os.environ:\n",
        "    del os.environ['http_proxy']\n",
        "    print(\"å·²æ¸…é™¤ http_proxy (å°å¯«)\")\n",
        "if 'https_proxy' in os.environ:\n",
        "    del os.environ['https_proxy']\n",
        "    print(\"å·²æ¸…é™¤ https_proxy (å°å¯«)\")\n",
        "\n",
        "# é‡æ–°å•Ÿå‹•æ‚¨çš„ Gradio æ‡‰ç”¨ç¨‹å¼\n",
        "# æ¥è‘—åŸ·è¡Œ genai.configure() å’Œ demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYn-JpreSqdl",
        "outputId": "0c0efa6a-a1f6-4ccf-cd86-0bee0be48f71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç•¶å‰ HTTP_PROXY: None\n",
            "ç•¶å‰ HTTPS_PROXY: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth, userdata\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "jHc_TCpMSuau"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl3ZQWAzSxcR",
        "outputId": "290f1148-561e-47d1-ed4c-8e1c9999e91e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import io\n",
        "import traceback\n",
        "import json\n",
        "import textwrap\n",
        "\n",
        "# å˜—è©¦å°å…¥ pypdf\n",
        "try:\n",
        "    from pypdf import PdfReader\n",
        "except ImportError:\n",
        "    PdfReader = None\n",
        "    print(\"âš ï¸ ç¼ºå°‘ pypdf å‡½å¼åº«ï¼ŒPDF è§£æåŠŸèƒ½å°‡ç„¡æ³•é‹ä½œã€‚è«‹åœ¨ Colab ä¸­åŸ·è¡Œ !pip install pypdf\")\n",
        "\n",
        "# å‡è¨­ auth.authenticate_user() å·²ç¶“åœ¨ Colab Notebook çš„é–‹é ­åŸ·è¡Œ\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# 1. é…ç½®èˆ‡å¸¸æ•¸é›†ä¸­å®šç¾© (å·²æ›´æ–°è¡¨é ­ï¼Œä¸¦**ç§»é™¤** 'ä¸Šå‚³æ–°èª²è¡¨' ç›¸é—œå¸¸æ•¸)\n",
        "# =========================================================\n",
        "class Config:\n",
        "    SHEET_URL = \"https://docs.google.com/spreadsheets/d/1DCt8Qn9mP8Q1PuLiMEW7Xd_hd3tzge8WJS5qsnRQ8mY/edit?gid=503414796#gid=503414796\"\n",
        "    WORKSHEET_NAME = \"èª²è¡¨\" # ä¸»èª²è¡¨åç¨±\n",
        "    SHEET_WEEKLY = \"æœ¬é€±é‡é»\"\n",
        "    SHEET_GEMINI_SUGGESTION = \"Geminiå»ºè­°\"\n",
        "    TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "    # === æ–°çš„ ä¸»èª²è¡¨ è¡¨é ­è¦æ±‚ (ç”¨æ–¼ WORKSHEET_NAME) ===\n",
        "    # é€™æ˜¯ PDF è§£æçš„ç›®æ¨™çµæ§‹ï¼Œå¿…é ˆåš´æ ¼éµå®ˆ\n",
        "    MAIN_TIMETABLE_HEADER = [\n",
        "        \"æ—¥æœŸ\", \"æ˜ŸæœŸ\", \"èª²ç¨‹åç¨±\", \"æ™‚é–“(èµ·)\", \"æ™‚é–“(è¿„)\",\n",
        "        \"åœ°é»\", \"æ”œå¸¶å“\", \"å…ˆè®€ç« ç¯€\", \"å‚™è¨»\"\n",
        "    ]\n",
        "\n",
        "    # æœ¬é€±é‡é» è¡¨é ­ (ä¿æŒä¸è®Š)\n",
        "    WEEKLY_HEADER = [\n",
        "        \"é€±æ¬¡èµ·è¨–\", \"æŸ¥è©¢æ˜ŸæœŸ\", \"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\", \"æ›´æ–°æ™‚é–“\",\n",
        "        \"è¡Œå‰æé†’ä¸€å¥è©±\", \"èª²ç¨‹æ‘˜è¦\", \"AIå­¸ç¿’å»ºè­°\", \"æ”œå¸¶å“\", \"å…ˆè®€ç« ç¯€\"\n",
        "    ]\n",
        "\n",
        "TW_TZ = pytz.timezone(Config.TIMEZONE)\n",
        "worksheets = {}\n",
        "model = None\n",
        "\n",
        "# 2. åˆå§‹åŒ–èˆ‡é€£ç·š (å¼·åˆ¶è¨­ç½®ä¸»èª²è¡¨è¡¨é ­)\n",
        "# =========================================================\n",
        "try:\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    gsheets = gc.open_by_url(Config.SHEET_URL)\n",
        "\n",
        "    # éœ€è¦é€£ç·šçš„å·¥ä½œè¡¨åç¨±\n",
        "    worksheet_names = [\n",
        "        Config.WORKSHEET_NAME, Config.SHEET_WEEKLY,\n",
        "        Config.SHEET_GEMINI_SUGGESTION\n",
        "    ]\n",
        "\n",
        "    for name in worksheet_names:\n",
        "        try:\n",
        "            ws = gsheets.worksheet(name)\n",
        "            worksheets[name] = ws\n",
        "\n",
        "            # **ç¢ºä¿ä¸»è¦èª²è¡¨ (Config.WORKSHEET_NAME) å…·æœ‰æ­£ç¢ºçš„è¡¨é ­**\n",
        "            if name == Config.WORKSHEET_NAME:\n",
        "                current_header = ws.row_values(1)\n",
        "                if current_header != Config.MAIN_TIMETABLE_HEADER:\n",
        "                    # æ¸…ç©ºä¸¦å¯«å…¥æ–°çš„è¡¨é ­\n",
        "                    ws.clear()\n",
        "                    ws.append_row(Config.MAIN_TIMETABLE_HEADER, value_input_option=\"USER_ENTERED\")\n",
        "                    print(f\"âš ï¸ '{name}' è¡¨é ­å·²æ›´æ–°ç‚º: {Config.MAIN_TIMETABLE_HEADER}\")\n",
        "\n",
        "\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # å‰µå»ºä¸å­˜åœ¨çš„å·¥ä½œè¡¨\n",
        "            if name == Config.SHEET_GEMINI_SUGGESTION:\n",
        "                ws = gsheets.add_worksheet(title=name, rows=\"200\", cols=\"3\")\n",
        "                ws.append_row([\"æ™‚é–“\", \"åˆ†æå°è±¡\", \"Gemini å»ºè­°/éŒ¯èª¤è¨Šæ¯\"], value_input_option=\"USER_ENTERED\")\n",
        "                worksheets[name] = ws\n",
        "            elif name == Config.SHEET_WEEKLY:\n",
        "                 ws = gsheets.add_worksheet(title=name, rows=\"100\", cols=len(Config.WEEKLY_HEADER))\n",
        "                 ws.append_row(Config.WEEKLY_HEADER, value_input_option=\"USER_ENTERED\")\n",
        "                 worksheets[name] = ws\n",
        "            elif name == Config.WORKSHEET_NAME:\n",
        "                 # å‰µå»ºä¸»èª²è¡¨ï¼Œä¸¦å¯«å…¥æ–°è¡¨é ­\n",
        "                 ws = gsheets.add_worksheet(title=name, rows=\"500\", cols=len(Config.MAIN_TIMETABLE_HEADER))\n",
        "                 ws.append_row(Config.MAIN_TIMETABLE_HEADER, value_input_option=\"USER_ENTERED\")\n",
        "                 worksheets[name] = ws\n",
        "            else:\n",
        "                 print(f\"âŒ æ‰¾ä¸åˆ°æˆ–ç„¡æ³•å‰µå»ºå·¥ä½œè¡¨: {name}\")\n",
        "\n",
        "    print(\"âœ… Google Sheets é€£ç·šæˆåŠŸã€‚\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Google Sheets é€£ç·šæˆ–è¨­ç½®å¤±æ•—: {e}\")\n",
        "\n",
        "try:\n",
        "    # é€™è£¡å‡è¨­æ‚¨çš„ API Key å·²åœ¨å¤–éƒ¨é…ç½®æˆ–å·²åœ¨ Notebook é ‚éƒ¨é‹è¡Œ\n",
        "    # genai.configure(api_key=\"AIzaSyAWyvSMGkAgiTMSdE8TEId8IFDw0OD46io\")\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    print(\"âœ… Gemini API é…ç½®æˆåŠŸã€‚\")\n",
        "except Exception as e:\n",
        "    model = None\n",
        "    print(f\"âŒ Gemini API é…ç½®å¤±æ•—: {e}\")\n",
        "\n",
        "# 3. å·¥å…·å‡½å¼ (èª¿æ•´ä»¥é©æ‡‰æ–°çš„æ¬„ä½åç¨±)\n",
        "# =========================================================\n",
        "\n",
        "def week_monday(any_date):\n",
        "    return any_date - dt.timedelta(days=any_date.weekday())\n",
        "\n",
        "def date_range_this_week(today=None):\n",
        "    now = dt.datetime.now(TW_TZ).date() if today is None else today\n",
        "    mon = week_monday(now)\n",
        "    sun = mon + dt.timedelta(days=6)\n",
        "    return mon, sun\n",
        "\n",
        "def wrap_text(text, limit=15):\n",
        "    \"\"\"å°‡é•·æ–‡æœ¬åœ¨ 15 å€‹å­—ç¬¦å¾Œæ›è¡Œï¼Œä¸¦ä¿ç•™åŸå§‹æ›è¡Œã€‚\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return text\n",
        "    paragraphs = text.split('\\n')\n",
        "    wrapped_content = []\n",
        "    for para in paragraphs:\n",
        "        if para.strip():\n",
        "            wrapped_content.append(textwrap.fill(para, width=limit, subsequent_indent=''))\n",
        "        else:\n",
        "            wrapped_content.append('')\n",
        "    return '\\n'.join(wrapped_content)\n",
        "\n",
        "def summarize_courses(day_df, format_type='detailed'):\n",
        "    \"\"\"æ•´ç†èª²ç¨‹æ–‡å­—å…§å®¹ï¼Œé©æ‡‰æ–°çš„æ¬„ä½åç¨±ï¼šæ™‚é–“(èµ·)/æ™‚é–“(è¿„) å’Œ åœ°é»ã€‚\"\"\"\n",
        "    if day_df.empty:\n",
        "        return \"æœ¬æ—¥ç„¡èª²\"\n",
        "\n",
        "    if format_type == 'detailed':\n",
        "        parts = []\n",
        "        # æ–°çš„æ¬„ä½åç¨±: èª²ç¨‹åç¨±, åœ°é», æ˜ŸæœŸ, æ™‚é–“(èµ·), æ™‚é–“(è¿„)\n",
        "        for _, r in day_df.iterrows():\n",
        "            name = r.get(\"èª²ç¨‹åç¨±\", \"\")\n",
        "            room = r.get(\"åœ°é»\", \"\") # å¾ 'åœ°é»' æ¬„ä½è®€å–\n",
        "            day = r.get(\"æ˜ŸæœŸ\", \"\")\n",
        "            time_start = r.get(\"æ™‚é–“(èµ·)\", \"\")\n",
        "            time_end = r.get(\"æ™‚é–“(è¿„)\", \"\")\n",
        "            # æ ¼å¼: èª²ç¨‹åç¨±(åœ°é»)[æ˜ŸæœŸ] [æ™‚é–“(èµ·)-æ™‚é–“(è¿„)]\n",
        "            parts.append(f\"{name}({room}){day} {time_start}-{time_end}\")\n",
        "        return \"\\n\".join(parts)\n",
        "\n",
        "    elif format_type == 'sheet_raw_items':\n",
        "        # æ”œå¸¶å“å’Œå…ˆè®€ç« ç¯€æ¬„ä½åç¨±ä¿æŒä¸è®Š\n",
        "        items = []\n",
        "        readings = []\n",
        "        for _, r in day_df.iterrows():\n",
        "            # å¿…é ˆæª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨ï¼Œå› ç‚º PDF è§£æå¯èƒ½æ²’æœ‰é€™äº›æ¬„ä½ï¼ˆä½†ç¾åœ¨å·²å¼·åˆ¶ç”¢ç”Ÿï¼‰\n",
        "            if \"æ”œå¸¶å“\" in r and str(r.get(\"æ”œå¸¶å“\", \"\")).strip():\n",
        "                items.append(str(r[\"æ”œå¸¶å“\"]).strip())\n",
        "            if \"å…ˆè®€ç« ç¯€\" in r and str(r.get(\"å…ˆè®€ç« ç¯€\", \"\")).strip():\n",
        "                readings.append(str(r[\"å…ˆè®€ç« ç¯€\"]).strip())\n",
        "\n",
        "        # ä½¿ç”¨åˆ†è™Ÿ ; ä½œç‚ºåˆ†éš”ç¬¦ï¼Œä¸¦å»é‡\n",
        "        items_txt = \"ï¼›\".join(dict.fromkeys(items)) if items else \"\"\n",
        "        read_txt = \"ï¼›\".join(dict.fromkeys(readings)) if readings else \"\"\n",
        "        return items_txt, read_txt\n",
        "\n",
        "    return \"æœ¬æ—¥ç„¡èª²\"\n",
        "\n",
        "# update_weekly_sheet_row å‡½å¼ (ä½¿ç”¨ Config.WEEKLY_HEADER)\n",
        "def update_weekly_sheet_row(target_weekday, row_data):\n",
        "    \"\"\"å°‡ç•¶æ—¥æ‰€æœ‰æ•¸æ“šå¯«å…¥/æ›´æ–°åˆ° 'æœ¬é€±é‡é»' åˆ†é çš„è¨˜éŒ„ (Upsert æ¨¡å¼)ã€‚\"\"\"\n",
        "    weekly_ws = worksheets.get(Config.SHEET_WEEKLY)\n",
        "    if not weekly_ws:\n",
        "        return \"âŒ Google Sheets 'æœ¬é€±é‡é»' æœªé€£ç·šã€‚\"\n",
        "\n",
        "    now_str = dt.datetime.now(TW_TZ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    today = dt.datetime.now(TW_TZ).date()\n",
        "    week_start, week_end = date_range_this_week(today)\n",
        "    current_date_range = f\"{week_start} ~ {week_end}\"\n",
        "    target_day_str = f\"æ˜ŸæœŸ{target_weekday}\"\n",
        "\n",
        "    all_values = weekly_ws.get_all_values()\n",
        "    header = Config.WEEKLY_HEADER\n",
        "    df_weekly = pd.DataFrame(columns=header)\n",
        "    status_action = \"æ–°å¢\"\n",
        "\n",
        "    if len(all_values) > 1:\n",
        "        header_read = all_values[0]\n",
        "        records = all_values[1:]\n",
        "        try:\n",
        "            df_weekly = pd.DataFrame(records, columns=header_read)\n",
        "        except:\n",
        "            df_weekly = pd.DataFrame(records)\n",
        "            df_weekly.columns = header_read[:len(df_weekly.columns)] if records and records[0] else header\n",
        "\n",
        "    update_fields = {\"æ›´æ–°æ™‚é–“\": now_str}\n",
        "    update_fields.update(row_data)\n",
        "\n",
        "    match_cols_exist = \"é€±æ¬¡èµ·è¨–\" in df_weekly.columns and \"æŸ¥è©¢æ˜ŸæœŸ\" in df_weekly.columns\n",
        "    is_matched = False\n",
        "    write_df = df_weekly\n",
        "\n",
        "    if match_cols_exist and not df_weekly.empty:\n",
        "        match_condition = (df_weekly[\"é€±æ¬¡èµ·è¨–\"] == current_date_range) & \\\n",
        "                          (df_weekly[\"æŸ¥è©¢æ˜ŸæœŸ\"] == target_day_str)\n",
        "\n",
        "        if match_condition.any():\n",
        "            update_index_in_df = df_weekly[match_condition].index[-1]\n",
        "            for key, value in update_fields.items():\n",
        "                if key in df_weekly.columns:\n",
        "                    # åˆ¤æ–·æ˜¯å¦ç‚º AI æˆ–é•·æ–‡æœ¬æ¬„ä½ï¼Œç¢ºä¿æ›´æ–°\n",
        "                    is_ai_or_required = key in Config.WEEKLY_HEADER[4:] or key in [\"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\", \"æ›´æ–°æ™‚é–“\"]\n",
        "                    if is_ai_or_required or (value != ''):\n",
        "                        df_weekly.loc[update_index_in_df, key] = value\n",
        "\n",
        "            write_df = df_weekly\n",
        "            status_action = \"æ›´æ–°\"\n",
        "            is_matched = True\n",
        "\n",
        "    if not is_matched:\n",
        "        new_row_data = {col: '' for col in Config.WEEKLY_HEADER}\n",
        "        new_row_data.update(update_fields)\n",
        "        new_row_data[\"é€±æ¬¡èµ·è¨–\"] = current_date_range\n",
        "        new_row_data[\"æŸ¥è©¢æ˜ŸæœŸ\"] = target_day_str\n",
        "\n",
        "        df_new_row = pd.DataFrame([new_row_data], columns=Config.WEEKLY_HEADER)\n",
        "        if not df_weekly.empty and all(col in df_weekly.columns for col in Config.WEEKLY_HEADER):\n",
        "             # ç¢ºä¿åˆä½µæ™‚åªä¿ç•™ WEEKLY_HEADER ä¸­çš„æ¬„ä½\n",
        "             write_df = pd.concat([df_weekly.reindex(columns=Config.WEEKLY_HEADER), df_new_row], ignore_index=True)\n",
        "        else:\n",
        "             write_df = df_new_row\n",
        "        status_action = \"æ–°å¢\"\n",
        "\n",
        "    if len(all_values) > 1:\n",
        "        weekly_ws.delete_rows(2, len(all_values))\n",
        "\n",
        "    if not write_df.empty:\n",
        "        # æœ€å¾Œä¸€æ¬¡ç¢ºä¿åˆ—é †åºæ­£ç¢º\n",
        "        write_df_cleaned = write_df.reindex(columns=Config.WEEKLY_HEADER)\n",
        "        set_with_dataframe(weekly_ws, write_df_cleaned, include_column_header=False, include_index=False, row=2)\n",
        "\n",
        "    return f\"âœ… '{Config.SHEET_WEEKLY}' åˆ†é {status_action}æˆåŠŸï¼\"\n",
        "\n",
        "\n",
        "def query_day_data(target_weekday):\n",
        "    \"\"\"æŸ¥è©¢æŒ‡å®šæ˜ŸæœŸçš„èª²ç¨‹ï¼Œä¸¦è¿”å›è©³ç´°åˆ—è¡¨å’Œåºåˆ—åŒ–çš„ DataFrameã€‚\"\"\"\n",
        "    ws = worksheets.get(Config.WORKSHEET_NAME)\n",
        "    if not ws:\n",
        "        return \"âŒ Google Sheets æœªæˆåŠŸé€£ç·šï¼Œç„¡æ³•è®€å–è³‡æ–™ã€‚\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        data = ws.get_all_values()\n",
        "        df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ç„¡æ³•è®€å–èª²è¡¨ï¼š{e}\", \"\", \"\"\n",
        "\n",
        "    # æ‰¾å‡ºè©²æ˜ŸæœŸçš„èª²ç¨‹\n",
        "    # æ³¨æ„ï¼šæ–°çš„è¡¨é ­åŒ…å« 'æ˜ŸæœŸ' æ¬„ä½ï¼Œå¯ä»¥ç›´æ¥æŸ¥è©¢\n",
        "    today_df = df[df[\"æ˜ŸæœŸ\"] == target_weekday].copy()\n",
        "\n",
        "    # æ ¼å¼åŒ–è©³ç´°èª²ç¨‹åˆ—è¡¨ (Gradio é¡¯ç¤ºç”¨)\n",
        "    detailed_list = summarize_courses(today_df, format_type='detailed')\n",
        "\n",
        "    if today_df.empty:\n",
        "        return f\"### ğŸ—“ï¸ æ˜ŸæœŸ{target_weekday} æœ¬æ—¥ç„¡èª²\", detailed_list, \"\"\n",
        "\n",
        "    # åºåˆ—åŒ– DataFrameï¼Œä»¥ä¾¿åœ¨ Gradio state ä¸­å‚³è¼¸\n",
        "    df_json = today_df.to_json(orient='records', force_ascii=False)\n",
        "\n",
        "    # ç²å–åŸå§‹æ”œå¸¶å“å’Œå…ˆè®€ç« ç¯€çš„åˆ—è¡¨ï¼Œä¾›å¯«å…¥ Google Sheet ä½¿ç”¨\n",
        "    items_txt, read_txt = summarize_courses(today_df, format_type='sheet_raw_items')\n",
        "\n",
        "    # å°‡åˆå§‹æ•¸æ“šå¯«å…¥ Sheet (å‰µå»ºæˆ–æ›¿æ›è©²æ—¥çš„è¨˜éŒ„)\n",
        "    row_data = {\n",
        "        \"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\": wrap_text(detailed_list.replace('\\n', 'ï¼›'), limit=15),\n",
        "        \"æ”œå¸¶å“\": items_txt,\n",
        "        \"å…ˆè®€ç« ç¯€\": read_txt,\n",
        "        \"è¡Œå‰æé†’ä¸€å¥è©±\": \"\",\n",
        "        \"èª²ç¨‹æ‘˜è¦\": \"\",\n",
        "        \"AIå­¸ç¿’å»ºè­°\": \"\",\n",
        "    }\n",
        "    sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "    title = f\"### ğŸ—“ï¸ æ˜ŸæœŸ{target_weekday} èª²ç¨‹åˆ—è¡¨\\n({sheet_status})\"\n",
        "    return title, detailed_list, df_json\n",
        "\n",
        "# 4. é€šç”¨ AI å…§å®¹ç”Ÿæˆå‡½å¼ (ç°¡åŒ–å¤šå€‹ AI å‡½å¼ç‚ºä¸€å€‹é€šç”¨å‡½å¼)\n",
        "# =========================================================\n",
        "\n",
        "AI_TASK_TEMPLATES = {\n",
        "    \"reminder\": {\n",
        "        \"prompt\": \"\"\"æ ¹æ“šä»¥ä¸‹ä»Šå¤©çš„èª²ç¨‹å®‰æ’å’Œæº–å‚™äº‹é …ï¼Œè«‹æ‰®æ¼”ä¸€ä½è¦ªåˆ‡çš„å­¸ç¿’å¤¥ä¼´ï¼Œç‚ºå­¸ç”Ÿå¯«ä¸€å€‹ç°¡çŸ­ã€æ´»æ½‘ã€å¸¶æœ‰ emoji çš„è¡Œå‰æé†’ã€‚è«‹å¾ã€Œæ”œå¸¶å“ã€å’Œã€Œå…ˆè®€ç« ç¯€ã€ä¸­æå–é—œéµä¿¡æ¯ï¼Œå°‡å¤šé …å…§å®¹æ•´åˆç‚ºä¸€å¥è©±æˆ–ä¸€æ®µè©±ã€‚è«‹åªè¼¸å‡ºæé†’å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\\nèª²ç¨‹æ¸…å–®ï¼š{data_str}\"\"\",\n",
        "        \"column\": \"è¡Œå‰æé†’ä¸€å¥è©±\",\n",
        "        \"wrap_limit\": 15,\n",
        "        \"label\": \"AI æé†’\",\n",
        "        \"input_type\": \"df\"\n",
        "    },\n",
        "    \"summary\": {\n",
        "        \"prompt\": \"\"\"æ ¹æ“šä»¥ä¸‹èª²ç¨‹è³‡è¨Šï¼Œè«‹ç”¨ä¸­æ–‡ç¸½çµã€Œæœ¬æ—¥çš„èª²ç¨‹ä¸»é¡Œå’Œå…§å®¹æ‘˜è¦ã€ã€‚è«‹ç”¨æ¢åˆ—å¼æˆ–çµæ§‹åŒ–çš„æ–¹å¼å‘ˆç¾ï¼Œä¸è¦è¶…é 150 å­—ã€‚è«‹åªè¼¸å‡ºæ‘˜è¦å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\\nèª²ç¨‹æ¸…å–®ï¼š{data_str}\"\"\",\n",
        "        \"column\": \"èª²ç¨‹æ‘˜è¦\",\n",
        "        \"wrap_limit\": 15,\n",
        "        \"label\": \"èª²ç¨‹æ‘˜è¦\",\n",
        "        \"input_type\": \"df\"\n",
        "    },\n",
        "    \"suggestion\": {\n",
        "        \"prompt\": \"\"\"æ ¹æ“šä»¥ä¸‹èª²ç¨‹å®‰æ’å’Œæº–å‚™äº‹é …ï¼Œç‚ºå­¸ç”Ÿæä¾› 2-3 é»å…·é«”çš„ã€Œæœ¬æ—¥å­¸ç¿’å»ºè­°ã€ã€‚å»ºè­°æ‡‰è‘—é‡æ–¼æ™‚é–“ç®¡ç†ã€èª²é–“ä¼‘æ¯ç­–ç•¥ã€ä»¥åŠå¦‚ä½•æœ€ä½³åŒ–å­¸ç¿’æ•ˆç‡ã€‚è«‹ç”¨ä¸­æ–‡æ¢åˆ—å¼æ¸…æ™°åœ°å›ç­”ï¼Œä¾‹å¦‚ï¼š1. ... 2. ...ã€‚è«‹åªè¼¸å‡ºå»ºè­°å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\\nèª²ç¨‹æ¸…å–®ï¼š{data_str}\"\"\",\n",
        "        \"column\": \"AIå­¸ç¿’å»ºè­°\",\n",
        "        \"wrap_limit\": 15,\n",
        "        \"label\": \"å­¸ç¿’å»ºè­°\",\n",
        "        \"input_type\": \"df\"\n",
        "    },\n",
        "    \"carry_items\": {\n",
        "        \"prompt\": \"\"\"æ ¹æ“šä»¥ä¸‹èª²ç¨‹ä¸­æåŠçš„åŸå§‹æ”œå¸¶å“åˆ—è¡¨ï¼Œè«‹å°‡å…¶æ•´ç†æˆ 2-3 å€‹ç²¾ç°¡çš„ä¸­æ–‡åˆ—é»å¼æ¸…å–®ã€‚å¦‚æœæ²’æœ‰æåŠå…·é«”ç‰©å“ï¼Œè«‹å»ºè­° 1-2 å€‹å¯¦ç”¨çš„ä¸€èˆ¬å­¸ç¿’ç”¨å“ã€‚è«‹åªè¼¸å‡ºåˆ—é»å¼æ¸…å–®ï¼Œæ¯å€‹åˆ—é»ä¸è¶…é 10 å€‹ä¸­æ–‡å­—ã€‚\\nåŸå§‹è³‡æ–™ï¼š{data_str}\"\"\",\n",
        "        \"column\": \"æ”œå¸¶å“\",\n",
        "        \"wrap_limit\": None,\n",
        "        \"label\": \"æ”œå¸¶å“å»ºè­°\",\n",
        "        \"input_type\": \"items\"\n",
        "    },\n",
        "    \"prereading\": {\n",
        "        \"prompt\": \"\"\"æ ¹æ“šä»¥ä¸‹èª²ç¨‹ä¸­æåŠçš„åŸå§‹å…ˆè®€ç« ç¯€åˆ—è¡¨ï¼Œè«‹å°‡å…¶æ•´ç†æˆ 2-3 å€‹ç²¾ç°¡çš„ä¸­æ–‡åˆ—é»å¼é ç¿’é‡é»ã€‚å¦‚æœæ²’æœ‰æŒ‡å®šç« ç¯€ï¼Œè«‹æä¾› 1-2 å€‹ä¸€èˆ¬æ€§çš„é ç¿’ç­–ç•¥å»ºè­°ã€‚è«‹åªè¼¸å‡ºåˆ—é»å¼æ¸…å–®ï¼Œæ¯å€‹åˆ—é»ä¸è¶…é 10 å€‹ä¸­æ–‡å­—ã€‚\\nåŸå§‹è³‡æ–™ï¼š{data_str}\"\"\",\n",
        "        \"column\": \"å…ˆè®€ç« ç¯€\",\n",
        "        \"wrap_limit\": None,\n",
        "        \"label\": \"å…ˆè®€ç« ç¯€å»ºè­°\",\n",
        "        \"input_type\": \"items\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def generate_and_update_ai_content(df_json, target_weekday, task_key):\n",
        "    \"\"\"é€šç”¨å‡½å¼ï¼šç”Ÿæˆ AI å…§å®¹ï¼Œä¸¦æ›´æ–° Google Sheet å°æ‡‰çš„æ¬„ä½ã€‚\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    task = AI_TASK_TEMPLATES[task_key]\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "\n",
        "        # æ ¹æ“šä»»å‹™é¡å‹æº–å‚™ data_str\n",
        "        if task[\"input_type\"] == \"items\":\n",
        "            items_txt, read_txt = summarize_courses(today_df, format_type='sheet_raw_items')\n",
        "            if task_key == \"carry_items\":\n",
        "                 data_str = f\"èª²ç¨‹ä¸­æåŠçš„æ”œå¸¶å“åŸå§‹åˆ—è¡¨ï¼š{items_txt}\"\n",
        "            else:\n",
        "                 data_str = f\"èª²ç¨‹ä¸­æåŠçš„å…ˆè®€ç« ç¯€åŸå§‹åˆ—è¡¨ï¼š{read_txt}\"\n",
        "            if not items_txt and task_key == \"carry_items\":\n",
        "                 data_str = \"èª²ç¨‹ä¸­æœªæåŠå…·é«”æ”œå¸¶å“ã€‚\"\n",
        "            if not read_txt and task_key == \"prereading\":\n",
        "                 data_str = \"èª²ç¨‹ä¸­æœªæåŠå…ˆè®€ç« ç¯€ã€‚\"\n",
        "        else:\n",
        "            data_str = today_df.to_string(index=False)\n",
        "\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = task[\"prompt\"].format(data_str=data_str)\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        raw_output = response.text.strip()\n",
        "\n",
        "        # æ‡‰ç”¨æ›è¡Œ (åªå°ç‰¹å®šæ¬„ä½æ‡‰ç”¨)\n",
        "        final_output = wrap_text(raw_output, limit=task[\"wrap_limit\"]) if task[\"wrap_limit\"] else raw_output\n",
        "\n",
        "        row_data = {task[\"column\"]: final_output}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return final_output, f\"âœ… {task['label']}å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ {task['label']}ç”Ÿæˆå¤±æ•—: {e}\"\n",
        "        # å˜—è©¦å¯«å…¥éŒ¯èª¤ä¿¡æ¯åˆ°å»ºè­°è¡¨\n",
        "        try:\n",
        "             suggestion_ws = worksheets.get(Config.SHEET_GEMINI_SUGGESTION)\n",
        "             now = dt.datetime.now(TW_TZ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "             suggestion_ws.append_row([now, f\"AIç”Ÿæˆå¤±æ•—:{task['label']}\", str(e)], value_input_option=\"USER_ENTERED\")\n",
        "        except:\n",
        "             pass\n",
        "        return error_msg, \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "\n",
        "# 5. æ•´é«”åˆ†æåŠŸèƒ½\n",
        "# =========================================================\n",
        "def gemini_analysis():\n",
        "    \"\"\"å‘¼å« Gemini API é€²è¡Œèª²è¡¨æ•´é«”åˆ†æï¼Œä¸¦å°‡çµæœå¯«å…¥ 'Geminiå»ºè­°' åˆ†é ã€‚\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚\"\n",
        "    ws = worksheets.get(Config.WORKSHEET_NAME)\n",
        "    suggestion_ws = worksheets.get(Config.SHEET_GEMINI_SUGGESTION)\n",
        "    if not ws or not suggestion_ws:\n",
        "        return \"âŒ Google Sheets æœªæˆåŠŸé€£ç·šï¼Œç„¡æ³•è®€å–è³‡æ–™æˆ–å¯«å…¥å»ºè­°ã€‚\"\n",
        "\n",
        "    now = dt.datetime.now(TW_TZ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    analysis_result = \"\"\n",
        "    feedback = \"\"\n",
        "\n",
        "    try:\n",
        "        all_data = ws.get_all_values()\n",
        "        if not all_data or len(all_data) < 2:\n",
        "            analysis_result = \"èª²è¡¨ä¸­ç›®å‰æ²’æœ‰è³‡æ–™ï¼Œç„¡æ³•åˆ†æã€‚\"\n",
        "            feedback = analysis_result\n",
        "        else:\n",
        "            df = pd.DataFrame(all_data[1:], columns=all_data[0])\n",
        "            preview = df.to_string(index=False)\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            é€™æ˜¯ä¸€ä»½å­¸ç”Ÿçš„èª²è¡¨ï¼ŒåŒ…å«æ—¥æœŸã€èª²ç¨‹åç¨±ã€æ˜ŸæœŸã€ä¸Šèª²æ™‚é–“(èµ·)ã€ä¸Šèª²æ™‚é–“(è¿„)ã€åœ°é»ã€æ”œå¸¶å“å’Œå…ˆè®€ç« ç¯€ç­‰è³‡è¨Šï¼š\n",
        "            {preview}\n",
        "\n",
        "            è«‹æ“”ä»»å­¸ç¿’é¡§å•ï¼Œæ ¹æ“šé€™ä»½èª²è¡¨ï¼š\n",
        "            1. æ•´ç†å‡ºå­¸ç”Ÿä¸€é€±çš„å­¸ç¿’è¶¨å‹¢ï¼Œä¾‹å¦‚å“ªå¤©èª²ç¨‹æœ€å¯†é›†ã€æ˜¯å¦æœ‰éœ€è¦ç‰¹åˆ¥æ³¨æ„çš„é€£å ‚èª²ã€‚\n",
        "            2. é‡å°ã€Œæ”œå¸¶å“ã€å’Œã€Œå…ˆè®€ç« ç¯€ã€çµ¦å‡ºç¶œåˆçš„ã€å…·é«”çš„æº–å‚™å»ºè­°ï¼ˆä¸åªæ˜¯åˆ—å‡ºæ¸…å–®ï¼Œè€Œæ˜¯å¦‚ä½•æº–å‚™ï¼‰ã€‚\n",
        "            3. é‡å°æ•´é«”èª²è¡¨ï¼Œçµ¦å‡º 2-3 å€‹æ™‚é–“ç®¡ç†æˆ–å­¸ç¿’æ–¹æ³•ä¸Šçš„å»ºè­°ã€‚\n",
        "            è«‹ç”¨ä¸­æ–‡æ¢åˆ—å¼æ¸…æ™°åœ°å›ç­”ã€‚\n",
        "            \"\"\"\n",
        "\n",
        "            response = model.generate_content(prompt, request_options={\"timeout\": 60})\n",
        "            analysis_result = response.text.strip()\n",
        "            feedback = \"âœ… Gemini åˆ†ææˆåŠŸï¼\"\n",
        "\n",
        "    except Exception as e:\n",
        "        analysis_result = f\"âŒ Gemini åˆ†ææ™‚ç™¼ç”Ÿ API éŒ¯èª¤ï¼š{e}\"\n",
        "        feedback = analysis_result\n",
        "\n",
        "    try:\n",
        "        suggestion_ws.append_row([now, \"æ•´é«”èª²è¡¨åˆ†æ\", analysis_result], value_input_option=\"USER_ENTERED\")\n",
        "        feedback += f\"\\nâœ… åˆ†æçµæœå·²å¯«å…¥ '{suggestion_ws.title}' åˆ†é ã€‚\"\n",
        "    except Exception as e:\n",
        "        feedback += f\"\\nâŒ å¯«å…¥ '{Config.SHEET_GEMINI_SUGGESTION}' åˆ†é å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "    return analysis_result + \"\\n\\n---\\n\" + feedback\n",
        "\n",
        "\n",
        "# 6. PDF è§£æèˆ‡ä¸Šå‚³åŠŸèƒ½ (**å¤§ä¿®**)\n",
        "# =========================================================\n",
        "def upload_and_process_pdf(pdf_file_path):\n",
        "    \"\"\"è§£æ PDF èª²è¡¨ï¼Œä¸¦å°‡è³‡æ–™å¯«å…¥ä¸»èª²è¡¨åˆ†é  (Config.WORKSHEET_NAME) ä¸¦è¦†è“‹ã€‚\"\"\"\n",
        "    ws = worksheets.get(Config.WORKSHEET_NAME)\n",
        "    df_empty = pd.DataFrame(columns=Config.MAIN_TIMETABLE_HEADER)\n",
        "\n",
        "    if not pdf_file_path: return \"âŒ å°šæœªä¸Šå‚³æª”æ¡ˆ\", df_empty\n",
        "    if not PdfReader: return \"âŒ pypdf å‡½å¼åº«æœªå®‰è£ï¼Œç„¡æ³•è®€å– PDF å…§å®¹ã€‚\", df_empty\n",
        "    if not model: return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ï¼Œç„¡æ³•é€²è¡Œ PDF è§£æã€‚\", df_empty\n",
        "    if not ws: return \"âŒ Google Sheets ä¸»èª²è¡¨åˆ†é æœªæˆåŠŸé€£ç·šã€‚\", df_empty\n",
        "\n",
        "    extracted_text = \"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_file_path)\n",
        "        for i, page in enumerate(reader.pages):\n",
        "            extracted_text += f\"--- Page {i+1} ---\\n\"\n",
        "            extracted_text += page.extract_text() or \"(ç„¡æ³•æå–æ–‡å­—)\"\n",
        "            extracted_text += \"\\n\\n\"\n",
        "\n",
        "        if not extracted_text.strip():\n",
        "            return \"âŒ PDF æª”æ¡ˆä¸­æœªè®€å–åˆ°ä»»ä½•æ–‡å­—å…§å®¹ï¼Œå¯èƒ½ç‚ºåœ–ç‰‡æƒææª”æˆ–æ ¼å¼ä¸æ”¯æ´ã€‚\", df_empty\n",
        "\n",
        "        required_columns = Config.MAIN_TIMETABLE_HEADER\n",
        "\n",
        "        # é‡å°æ–°çš„ 9 æ¬„çµæ§‹ï¼Œå„ªåŒ–æç¤ºè©ï¼Œç‰¹åˆ¥å¼·èª¿æ—¥æœŸå’Œæ™‚é–“æ‹†åˆ†\n",
        "        prompt = f\"\"\"\n",
        "        è«‹åˆ†æä»¥ä¸‹å¾èª²è¡¨ PDF ä¸­æå–å‡ºçš„æ–‡å­—å…§å®¹ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡èª²ç¨‹è³‡è¨Šæ•´ç†æˆä¸€å€‹æ¨™æº–çš„ CSV æ ¼å¼ã€‚\n",
        "        è«‹åš´æ ¼ç¢ºä¿è¼¸å‡ºå…§å®¹**åªæœ‰** CSV æ ¼å¼çš„æ•¸æ“šï¼Œä¸åŒ…å«ä»»ä½•é¡å¤–èªªæ˜æ–‡å­—æˆ–Markdownæ¨™è¨˜ (å¦‚ ```csv)ã€‚\n",
        "\n",
        "        CSV çš„æ¨™é ­è¡Œ (Header) **å¿…é ˆ**å®Œå…¨åŒ…å«ä»¥ä¸‹ {len(required_columns)} å€‹æ¬„ä½ï¼Œä¸”é †åºä¸è®Šï¼š\n",
        "        {','.join(required_columns)}\n",
        "\n",
        "        è«‹æ ¹æ“š PDF å…§å®¹ï¼Œå°‡èª²è¡¨æ•¸æ“šå¡«å…¥é€™äº›æ¬„ä½ã€‚\n",
        "        1. ã€Œæ—¥æœŸã€æ¬„ä½ï¼šè«‹æ ¹æ“šèª²è¡¨ä¸Šçš„è³‡è¨Šæˆ–æ¨ç®—ï¼Œå¡«å¯«èª²ç¨‹å°æ‡‰çš„æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)ã€‚\n",
        "        2. ã€Œæ™‚é–“(èµ·)ã€å’Œã€Œæ™‚é–“(è¿„)ã€ï¼šè«‹å°‡åŸå§‹èª²è¡¨ä¸­çš„ä¸Šèª²æ™‚é–“æ‹†åˆ†æˆé€™å…©å€‹æ¬„ä½ã€‚\n",
        "        3. ã€Œåœ°é»ã€æ¬„ä½ï¼šè«‹å¡«å¯«ä¸Šèª²æ•™å®¤åç¨±ã€‚\n",
        "        4. ã€Œæ”œå¸¶å“ã€ã€ã€Œå…ˆè®€ç« ç¯€ã€ã€ã€Œå‚™è¨»ã€æ¬„ä½ï¼šå¦‚æœåŸå§‹ PDF ä¸­æ²’æœ‰æ˜ç¢ºè³‡è¨Šï¼Œè«‹å‹™å¿…ç•™ç©º (Empty/ç©ºç™½)ã€‚\n",
        "        5. ã€Œæ˜ŸæœŸã€ï¼šè«‹å‹™å¿…ç”¨ä¸­æ–‡æ•¸å­—ã€Œä¸€ã€äºŒã€ä¸‰ã€å››ã€äº”ã€å…­ã€æ—¥ã€è¡¨ç¤ºã€‚\n",
        "\n",
        "        --- PDF å…§å®¹é–‹å§‹ ---\n",
        "        {extracted_text.strip()}\n",
        "        --- PDF å…§å®¹çµæŸ ---\n",
        "        \"\"\"\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 120})\n",
        "        csv_text = response.text.strip().replace(\"```csv\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "        df_parsed = pd.read_csv(io.StringIO(csv_text))\n",
        "\n",
        "        # åš´æ ¼æª¢æŸ¥æ¬„ä½æ˜¯å¦é½Šå…¨\n",
        "        if not all(col in df_parsed.columns for col in required_columns):\n",
        "            missing_cols = [col for col in required_columns if col not in df_parsed.columns]\n",
        "            raise ValueError(f\"Gemini è¼¸å‡ºçš„æ¬„ä½ä¸å®Œæ•´æˆ–ä¸æ­£ç¢ºã€‚ç¼ºå°‘æ¬„ä½: {missing_cols}\")\n",
        "\n",
        "        df_final = df_parsed[required_columns].copy()\n",
        "\n",
        "        # æ¸…ç†æ—¥æœŸæ¬„ä½ï¼šç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢ºï¼Œå¦‚æœæ—¥æœŸä¸ç¢ºå®šæˆ–ç‚ºç©ºï¼Œå‰‡è¨­ç‚ºç©ºå­—ä¸²\n",
        "        df_final['æ—¥æœŸ'] = df_final['æ—¥æœŸ'].astype(str).str.strip().apply(\n",
        "            lambda x: dt.datetime.strptime(x, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
        "            if pd.notna(x) and x.count('-') == 2 and len(x) >= 10 else ''\n",
        "        )\n",
        "\n",
        "        # å¯«å…¥ä¸»èª²è¡¨ (WORKSHEET_NAME) ä¸¦è¦†è“‹åŸè³‡æ–™\n",
        "        ws.clear()\n",
        "        ws.append_row(required_columns, value_input_option=\"USER_ENTERED\")\n",
        "        set_with_dataframe(ws, df_final, include_column_header=False, include_index=False)\n",
        "\n",
        "        status_msg = f\"âœ… PDF èª²è¡¨è§£ææˆåŠŸï¼å·²å°‡ {len(df_final)} ç­†è³‡æ–™å¯«å…¥ä¸»èª²è¡¨ '{ws.title}' åˆ†é ï¼Œä¸¦é¡¯ç¤ºæ–¼ä¸‹æ–¹é è¦½ã€‚\"\n",
        "        return status_msg, df_final\n",
        "\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        status_msg = f\"âŒ è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\\n\\nè«‹æª¢æŸ¥ PDF æ ¼å¼ã€AI è¼¸å‡ºæˆ–è¡¨é ­æ˜¯å¦æ­£ç¢ºã€‚\"\n",
        "        print(f\"--- ERROR DETAILS ---\\n{error_details}\\n---------------------\")\n",
        "        return status_msg, df_empty\n",
        "\n",
        "\n",
        "# 7. Gradio ä»‹é¢ (**èª¿æ•´æ¬„ä½é¡¯ç¤º**)\n",
        "# =========================================================\n",
        "with gr.Blocks(title=\"æ™ºæ…§èª²è¡¨æŸ¥çœ‹ç³»çµ±\") as demo:\n",
        "    gr.Markdown(\"# ğŸ“ æ™ºæ…§èª²è¡¨æŸ¥çœ‹ç³»çµ±ï¼ˆAI å¼·åŒ–ç‰ˆï¼‰\")\n",
        "    gr.Markdown(f\"ä¸»èª²è¡¨ ('{Config.WORKSHEET_NAME}') å·²æ›´æ–°ç‚ºæ‚¨è¦æ±‚çš„ 9 å€‹æ¬„ä½çµæ§‹ã€‚\")\n",
        "\n",
        "    day_df_json_state = gr.State(\"\")\n",
        "    query_weekday_state = gr.State(\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # --- åˆ†é 1ï¼šä¸Šå‚³ PDF (ç¾åœ¨ç›´æ¥å¯«å…¥ä¸»èª²è¡¨) ---\n",
        "        with gr.Tab(f\"ğŸ“¤ ä¸Šå‚³/è¦†è“‹èª²è¡¨ PDF (å¯«å…¥ '{Config.WORKSHEET_NAME}')\"):\n",
        "            gr.Markdown(f\"### ğŸ“„ è§£æ PDF èª²è¡¨ä¸¦**è¦†è“‹**å¯«å…¥ä¸»èª²è¡¨åˆ†é  ('{Config.WORKSHEET_NAME}')\")\n",
        "            pdf_file = gr.File(label=\"è«‹ä¸Šå‚³èª²è¡¨ PDF æª”æ¡ˆ\", file_types=[\".pdf\"])\n",
        "            upload_btn = gr.Button(\"è§£æ PDF ä¸¦è¦†è“‹å¯«å…¥ Google Sheets\")\n",
        "            upload_output = gr.Markdown()\n",
        "            df_output = gr.Dataframe(\n",
        "                label=f\"è§£æå¾Œçš„èª²è¡¨é è¦½ (å°‡è¦†è“‹ '{Config.WORKSHEET_NAME}' åˆ†é )\",\n",
        "                headers=Config.MAIN_TIMETABLE_HEADER, # ä½¿ç”¨æ–°çš„ 9 æ¬„è¡¨é ­\n",
        "                datatype=[\"str\"] * len(Config.MAIN_TIMETABLE_HEADER),\n",
        "                wrap=True,\n",
        "            )\n",
        "            upload_btn.click(\n",
        "                upload_and_process_pdf,\n",
        "                inputs=[pdf_file],\n",
        "                outputs=[upload_output, df_output]\n",
        "            )\n",
        "\n",
        "        # --- åˆ†é 2ï¼šæŸ¥è©¢èª²ç¨‹ ---\n",
        "        with gr.Tab(\"ğŸ“… æŸ¥è©¢èª²ç¨‹\"):\n",
        "            with gr.Column():\n",
        "                weekday_dropdown = gr.Dropdown(\n",
        "                    label=\"é¸æ“‡æ˜ŸæœŸ\",\n",
        "                    choices=[\"ä¸€\",\"äºŒ\",\"ä¸‰\",\"å››\",\"äº”\",\"å…­\",\"æ—¥\"],\n",
        "                    value=\"ä¸€\" # é è¨­æ”¹ç‚ºæ˜ŸæœŸä¸€\n",
        "                )\n",
        "                query_btn = gr.Button(\"æŸ¥è©¢èª²ç¨‹ä¸¦æº–å‚™ AI åˆ†æ\")\n",
        "\n",
        "                output_title = gr.Markdown()\n",
        "                # æç¤ºæ–‡å­—å·²æ›´æ–°ä»¥é©æ‡‰æ–°çš„æ¬„ä½æ ¼å¼\n",
        "                output_detailed_list = gr.Textbox(label=\"ç•¶æ—¥èª²ç¨‹è©³ç´°åˆ—è¡¨ (æ ¼å¼: èª²ç¨‹åç¨±(åœ°é»)æ˜ŸæœŸ æ™‚é–“(èµ·)-æ™‚é–“(è¿„))\", lines=10, type=\"text\", interactive=False)\n",
        "\n",
        "                query_btn.click(\n",
        "                    query_day_data,\n",
        "                    inputs=[weekday_dropdown],\n",
        "                    outputs=[output_title, output_detailed_list, day_df_json_state],\n",
        "                ).then(\n",
        "                    lambda w: w,\n",
        "                    inputs=[weekday_dropdown],\n",
        "                    outputs=[query_weekday_state]\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### ğŸ§  AI èª²ç¨‹æº–å‚™èˆ‡å»ºè­° (çµæœå°‡å¯«å…¥ã€æœ¬é€±é‡é»ã€)\")\n",
        "\n",
        "                # AI å€å¡Š (ä½¿ç”¨é€šç”¨å‡½å¼)\n",
        "                with gr.Row():\n",
        "                    ai_reminder_btn = gr.Button(\"âœ¨ AI è¡Œå‰æé†’\")\n",
        "                    ai_summary_btn = gr.Button(\"ğŸ“ AI èª²ç¨‹æ‘˜è¦\")\n",
        "                    ai_suggestion_btn = gr.Button(\"ğŸ’¡ AI å­¸ç¿’å»ºè­°\")\n",
        "                    ai_carry_btn = gr.Button(\"ğŸ’ AI æ”œå¸¶å“å»ºè­°\")\n",
        "                    ai_preread_btn = gr.Button(\"ğŸ“– AI å…ˆè®€ç« ç¯€å»ºè­°\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    ai_reminder_output = gr.Textbox(label=\"ğŸ“£ è¡Œå‰æé†’\", lines=3, type=\"text\", interactive=False, scale=1)\n",
        "                    ai_summary_output = gr.Textbox(label=\"ğŸ“ èª²ç¨‹æ‘˜è¦\", lines=3, type=\"text\", interactive=False, scale=1)\n",
        "                    ai_suggestion_output = gr.Textbox(label=\"ğŸ’¡ å­¸ç¿’å»ºè­°\", lines=3, type=\"text\", interactive=False, scale=1)\n",
        "                    ai_carry_output = gr.Textbox(label=\"ğŸ’ æ”œå¸¶å“\", lines=3, type=\"text\", interactive=False, scale=1)\n",
        "                    ai_preread_output = gr.Textbox(label=\"ğŸ“– å…ˆè®€ç« ç¯€\", lines=3, type=\"text\", interactive=False, scale=1)\n",
        "\n",
        "                ai_status = gr.Markdown()\n",
        "\n",
        "                # ç¶å®šé€šç”¨å‡½å¼\n",
        "                ai_reminder_btn.click(\n",
        "                    lambda df, wd: generate_and_update_ai_content(df, wd, \"reminder\"),\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_reminder_output, ai_status]\n",
        "                )\n",
        "                ai_summary_btn.click(\n",
        "                    lambda df, wd: generate_and_update_ai_content(df, wd, \"summary\"),\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_summary_output, ai_status]\n",
        "                )\n",
        "                ai_suggestion_btn.click(\n",
        "                    lambda df, wd: generate_and_update_ai_content(df, wd, \"suggestion\"),\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_suggestion_output, ai_status]\n",
        "                )\n",
        "                ai_carry_btn.click(\n",
        "                    lambda df, wd: generate_and_update_ai_content(df, wd, \"carry_items\"),\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_carry_output, ai_status]\n",
        "                )\n",
        "                ai_preread_btn.click(\n",
        "                    lambda df, wd: generate_and_update_ai_content(df, wd, \"prereading\"),\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_preread_output, ai_status]\n",
        "                )\n",
        "\n",
        "\n",
        "        # --- åˆ†é 3ï¼šGemini åˆ†æå»ºè­° ---\n",
        "        with gr.Tab(\"ğŸ¤– AI èª²è¡¨æ•´é«”åˆ†æ\"):\n",
        "            gr.Markdown(\"### ğŸ§  æ ¹æ“šæ‚¨çš„å®Œæ•´èª²è¡¨é€²è¡Œå­¸ç¿’è¶¨å‹¢èˆ‡æº–å‚™å»ºè­°åˆ†æ\")\n",
        "            ai_btn = gr.Button(\"ç”¢ç”Ÿ AI åˆ†æå»ºè­°\")\n",
        "            ai_output = gr.Textbox(label=\"Gemini åˆ†æçµæœèˆ‡å›é¥‹\", lines=15)\n",
        "\n",
        "            ai_btn.click(fn=gemini_analysis, inputs=None, outputs=ai_output)\n",
        "\n",
        "# å•Ÿå‹• Gradio App\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True, share=True, inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "slZT1zQQbjN3",
        "outputId": "05607741-a66b-4ccb-f9ca-06fa8129478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Sheets é€£ç·šæˆåŠŸã€‚\n",
            "âœ… Gemini API é…ç½®æˆåŠŸã€‚\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0778dd7aac3591cc6b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0778dd7aac3591cc6b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1134, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 125, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 111, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 391, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e56dc6816d0 [unset]> is bound to a different event loop\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 1298.08ms\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'æ˜ŸæœŸ'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 759, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2116, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1623, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2459892659.py\", line 261, in query_day_data\n",
            "    today_df = df[df[\"æ˜ŸæœŸ\"] == target_weekday].copy()\n",
            "                  ~~^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\", line 4102, in __getitem__\n",
            "    indexer = self.columns.get_loc(key)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'æ˜ŸæœŸ'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'æ˜ŸæœŸ'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\", line 759, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2116, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 1623, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/utils.py\", line 915, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2459892659.py\", line 261, in query_day_data\n",
            "    today_df = df[df[\"æ˜ŸæœŸ\"] == target_weekday].copy()\n",
            "                  ~~^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\", line 4102, in __getitem__\n",
            "    indexer = self.columns.get_loc(key)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'æ˜ŸæœŸ'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVcJrvL8L+BEti2Yzp3zP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}